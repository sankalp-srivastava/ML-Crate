{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER2JwWQssa9z",
        "outputId": "3cd49c99-263f-4ecc-d008-f154e17cccdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5QTFd2Tws1x1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import random\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_gen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "# test set need to be rescaled\n",
        "test_gen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "4mjkDvUioVCL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EirKdtvhtCs_",
        "outputId": "12edfcc1-c39b-47b8-8f93-9b8a75db20d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8018 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = data_gen.flow_from_directory(\"/content/drive/MyDrive/jwoc_dag_cat/dataset/training_set\",\n",
        "                                          target_size=(150,150),\n",
        "                                          batch_size = 32,\n",
        "                                          class_mode = 'binary')\n",
        "                                         \n",
        "test_dataset = test_gen.flow_from_directory(\"/content/drive/MyDrive/jwoc_dag_cat/dataset/test_set\",\n",
        "                                          target_size=(150,150),\n",
        "                                          batch_size =32,\n",
        "                                          class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MTsBLImiuRlq"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "# Convolutional layer and maxpool layer 1\n",
        "model.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "\n",
        "# Convolutional layer and maxpool layer 2\n",
        "model.add(keras.layers.Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "\n",
        "# Convolutional layer and maxpool layer 3\n",
        "model.add(keras.layers.Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "\n",
        "\n",
        "# This layer flattens the resulting image array to 1D array\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
        "model.add(keras.layers.Dense(512,activation='relu'))\n",
        "\n",
        "# Output layer with single neuron which gives 0 for Cat or 1 for Dog \n",
        "#Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
        "model.add(keras.layers.Dense(1,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nW4ROO4covU7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset,\n",
        "         epochs = 25,\n",
        "         validation_data = test_dataset\n",
        "       \n",
        "         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyYa-6q4oxJp",
        "outputId": "8029b4a1-0971-4ee5-dd9c-b7b7601e9799"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "251/251 [==============================] - 2092s 8s/step - loss: 0.7037 - accuracy: 0.5277 - val_loss: 0.6768 - val_accuracy: 0.5730\n",
            "Epoch 2/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.6757 - accuracy: 0.5821 - val_loss: 0.6636 - val_accuracy: 0.6330\n",
            "Epoch 3/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.6580 - accuracy: 0.6171 - val_loss: 0.6290 - val_accuracy: 0.6655\n",
            "Epoch 4/25\n",
            "251/251 [==============================] - 274s 1s/step - loss: 0.6360 - accuracy: 0.6369 - val_loss: 0.5995 - val_accuracy: 0.6865\n",
            "Epoch 5/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.6104 - accuracy: 0.6672 - val_loss: 0.5577 - val_accuracy: 0.7195\n",
            "Epoch 6/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.5830 - accuracy: 0.6982 - val_loss: 0.5305 - val_accuracy: 0.7445\n",
            "Epoch 7/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.5762 - accuracy: 0.6968 - val_loss: 0.5283 - val_accuracy: 0.7525\n",
            "Epoch 8/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.5614 - accuracy: 0.7104 - val_loss: 0.5080 - val_accuracy: 0.7400\n",
            "Epoch 9/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.5580 - accuracy: 0.7151 - val_loss: 0.5067 - val_accuracy: 0.7420\n",
            "Epoch 10/25\n",
            "251/251 [==============================] - 274s 1s/step - loss: 0.5380 - accuracy: 0.7319 - val_loss: 0.4804 - val_accuracy: 0.7620\n",
            "Epoch 11/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.5206 - accuracy: 0.7388 - val_loss: 0.4981 - val_accuracy: 0.7490\n",
            "Epoch 12/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.5238 - accuracy: 0.7418 - val_loss: 0.4749 - val_accuracy: 0.7765\n",
            "Epoch 13/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.5123 - accuracy: 0.7501 - val_loss: 0.4671 - val_accuracy: 0.7870\n",
            "Epoch 14/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.5083 - accuracy: 0.7492 - val_loss: 0.4550 - val_accuracy: 0.7845\n",
            "Epoch 15/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.4978 - accuracy: 0.7574 - val_loss: 0.4448 - val_accuracy: 0.7905\n",
            "Epoch 16/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.4906 - accuracy: 0.7680 - val_loss: 0.4300 - val_accuracy: 0.8110\n",
            "Epoch 17/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.4782 - accuracy: 0.7648 - val_loss: 0.4476 - val_accuracy: 0.7950\n",
            "Epoch 18/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.4768 - accuracy: 0.7645 - val_loss: 0.4238 - val_accuracy: 0.8070\n",
            "Epoch 19/25\n",
            "251/251 [==============================] - 273s 1s/step - loss: 0.4676 - accuracy: 0.7761 - val_loss: 0.4106 - val_accuracy: 0.8185\n",
            "Epoch 20/25\n",
            "251/251 [==============================] - 280s 1s/step - loss: 0.4640 - accuracy: 0.7789 - val_loss: 0.3959 - val_accuracy: 0.8205\n",
            "Epoch 21/25\n",
            "251/251 [==============================] - 274s 1s/step - loss: 0.4580 - accuracy: 0.7821 - val_loss: 0.4137 - val_accuracy: 0.8060\n",
            "Epoch 22/25\n",
            "251/251 [==============================] - 274s 1s/step - loss: 0.4575 - accuracy: 0.7864 - val_loss: 0.3834 - val_accuracy: 0.8280\n",
            "Epoch 23/25\n",
            "251/251 [==============================] - 274s 1s/step - loss: 0.4373 - accuracy: 0.7960 - val_loss: 0.3962 - val_accuracy: 0.8210\n",
            "Epoch 24/25\n",
            "251/251 [==============================] - 275s 1s/step - loss: 0.4377 - accuracy: 0.7978 - val_loss: 0.3875 - val_accuracy: 0.8220\n",
            "Epoch 25/25\n",
            "251/251 [==============================] - 275s 1s/step - loss: 0.4246 - accuracy: 0.8012 - val_loss: 0.3769 - val_accuracy: 0.8340\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1a3f26150>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zzxxTpoEo0yz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "dog_cat_image_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}